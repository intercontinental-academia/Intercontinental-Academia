---
tags:
- Distributed Intelligence
- Bhevaiour
- Installation Theory
- Social Cognition
- Language
- Robots
- Agency
- Internet of Things
published: true
pinned: false
post_title: 'Day 3: "What you do FOR  people, you do TO people, so do it WITH people!"'
date: 2021-10-19T23:00:00Z
authors:
- name: Atrina Oraee
images:
- "/snapseed-5.png"
- "/snapseed-8.png"
- "/snapseed-10.png"
- "/snapseed-6.png"
- "/snapseed-9.png"
- "/fullsizerender-2.jpg"
- "/snapseed-7.png"
- "/img_4552.jpg"
youtube_video_id: ''
audio: []

---
Day 3 of the first session of ICA4 continued in Paris IAS, where the Fellows sat through three more scientific seminars, followed by discussions and brainstorming sessions.  

The day kicked off by a framework proposed by [_Saadi Lahlou_](/about/ica4#lahlou "Saadi Lahlou"), called **"Installation Theory"**, which enables scientists to **analyse and regulate human behaviour**. This was complemented by a new technique to **capture the subjective perception of action**, ultimately bringing psychological and behavioural sciences one step closer to what was once considered a technically impossible task: **introspection!**

[_William Hopkins_](/mentors#hopkins "William Hopkins") then joined the discussions with some stimulating videos from research done on **apes**, while exploring **self-recognition and social cognition in animals**.

Finally, Toshio Fukuda revealed the Moonshot project: **a society where humans and robots live together in 2050!**<!--more-->

**Distributed Intelligence & Distributed Agency**

Presented by [**_Saadi Lahlou_**](/about/ica4#lahlou "Saadi Lahlou")

We want intelligence to perform relevantly adapted actions that change the situation in which we are for the better. To design intelligence, we must first understand **the nature of the actual activity**. In this sense, the behaviour was defined as what people do, seen from the outside. In other words, behaviour remains an external description of objective phenomena. This is while activity is how people subjectively perceive their action and how they see it from their own perspective.

**Installations consist of components that simultaneously support and control**. In other words, they are specific, local, and societal settings where humans are expected to behave predictably, e.g., airport, metro, cash machine, etc. **Installations** consist of **three** layers: **affordances of the physical environment, embodied competencies and social regulations.** Intelligence is thus **distributed** over these three layers.

The question now is: why do we have these installations? Because **installations channel many of our behaviours** and consequently make us very efficient, although our short memory and cognitive processing are very limited compared to animals. Installations are **redundant**, and redundancy produces resilience and learning.

Moreover, certain questions on designing trade-off issues were raised: which agency for whom? AI agent? what kind of competence for the AI? What affordances? What rules? What degree of awareness? To whom does the agent report? How is it evaluated? He also added the “privacy dilemma.” In other words, for better service, one must disclose information. Is there an “agency dilemma”? Can we make it explicit? Because the agency is distributed, so the responsibility is shared. It means that we now have the “many hands" problem. Thus, credentials for AI were suggested, which include **values** (what does it try to optimise), **ownership** (who takes responsibility for its actions), **principles of action** (rules, algorithms, domain of awareness and action), **track record** (list of transactions executed, includes initial training).

To conclude, ICA4 Fellows were left with some questions as food for thought. For each activity, do we want to augment existing agents with more agency? If so, which ones? Humans? Material objects? Social system? New agents? Who learns what? What values do we want to foster? What do we want AI for must be addressed for each activity, starting from the activity and discussed?

**Perspective on Artificial Intelligence research from studies on Agency, self-recognition and social cognition in animals**

Presented by [**_William Hopkins_**](/mentors#hopkins "William Hopkins")

The session began by discussing humans constructed concepts to reflect intellectual abilities in various domains of cognitive functions. In this sense, we use tests like the WAIS or Stanford Binet to quantify and scale performance to standards for specific age classes. These tests rely heavily on language. There are many approaches to developing fair tests of cognition between species with different sensory and motor capabilities. It began with Darwin and Furness. Then, George Romanes (1884) focused on animal intelligence and later on, Kohler (1925) on insight learning. Within the same field, Robert Yerkes (1916) worked on “The mental life of monkeys and apes: a study of ideational behavior”. Yerkes later developed the IQ test used by the army in WW1 (army alpha test).

Upon drawing on some of the literature, several videos were played, in which apes carries out various tasks including retrieving a peanut in the bottom of a tube followed by a video from an ape imitating a human, and so on. Several animals passed the mark test. E.g., magpies with a yellow stick in their neck can identify it and try to remove using the mirror. Cortical parcellation of chimpanzee brain - compared to humans, the ones that passed the test show differences in some cortices. Grey matter differences between MSR+ vs. MSR-. They also analysed the anterior cingulate since such neurones are rather long and connect the anterior cingulate with the insula.

Moreover, results from studies that showed that human children outperformed apes on the social, but not physical, cognition tasks were presented and discussed. Much like the research in AI, Most early comparative studies of cognition and intelligence were strongly rooted in associative learning theory. However, associative or operant theories of learning were and are notoriously anti-cognitive. In the 1960s, there were attempts to reach apes alternative communication systems. The goal of the ape language studies was to determine whether language is uniquely human. The answer depends on how we define language.

However, is it language? There is very little evidence for declarative production (e.g., turn on the TV, give me an onion) in communication signals by primates and other animals. The other question is: are social stimuli rewarding? For chimpanzees, yes. Experiment: touch one button to see other chimpanzees or another button to see random animals. The chimp chose to press the button to see other chimps. Thus, the role of reward guides the learning and behaviour of animals. Although animal cognition is often used to explain animal behaviour, most can be explained by an associative learning mechanism.

**AI and Robots for Future: The Moon Shot Project**

Presented by [**_Toshio Fukuda_**](/mentors#fukuda "Toshio Fukuda")

Robots are avatars that pop up to help when humans need them. There is an information and physical interaction between robots and humans. Toshio showed several multi-scale robots, e.g., monkey-type robots, multi-locomotion, intelligent cane, etc. One of these robots is the Brachiator I-III. Brachiation is a form of long-armed ape locomotion. It uses dynamics of the pendulum, under-actuated mechanical system, variable constraint system, machine learning, AI, reinforce learning, soft computing (fuzzy, genetic algorithm). Regarding multi-locomotion types, in many cases, one creature has multiple types of locomotion in order to improve its mobility. The motivation of their study is to develop a robot mechanism and a control architecture that can achieve multiple locomotions. Hybrid computational intelligence, i.e., AI and brain interface were also commented upon by the speaker while showing a series of related videos. An example of such videos illustrated the Boston dynamics atlas and others: three robots dancing and jumping which was quite impressive!

Moreover, AI+Robot+IoT (Internet of Things), the use of robots in mega-trend (energy, urbanisation, food, ageing, global warming, robot, and AI) were discussed. This was followed by further discussions on autonomous cars, which may be safer than human drivers, mixed reality, the Eve project (a transparent body that simulates the human body), cyborg technology (fusion of robot and animal), and multiple robots (communication among robots).

Scribe: [_André Fujita_](/fellows#fujita "Andre Fujita")

Chair: [_Philipp Kellmeyer_](/fellows#kellmeyer "Philipp Kellmeyer")