---
tags:
- Artificial Intelligence
- Challenges
- ICA4
- Session 1
- Paris
published: true
pinned: false
post_title: The challenges of Artificial Intelligence (AI) in the upcoming decades
date: 2021-10-18T22:00:00.000+00:00
authors:
- name: Atrina Oraee
image: "/snapseed-3.jpg"
youtube_video_id: ''
audio: []
images:
- "/img_4328.jpg"
- "/snapseed-5.jpg"
- "/snapseed-4.jpg"

---
While impossible to precisely predict, the convoluted future of AI may be presented in terms of **some major challenges it will inevitably face within the upcoming decades**. The ICA4 Mentors  shared their views and thoughts on this fascinating, and intellectually challenging, subject over a roundtable discussion in the halls of Paris IAS!<!--more-->

[**Professor Saadi Lahlou**](https://www.intercontinental-academia.org/about/ica4#lahlou "Saadi Lahlou") described the progress of sensors and actuators as a massive transformation. He further explained that there are already billions of them connected to the network, but not interconnected yet. The “Internet of Things” may operate such an interconnection by connecting perception and action systems (which are precisely the before mentioned sensors and actuators) to the information processing systems. Consequently, this can create, on a colossal scale, the **perception-reasoning-action loop** that characterises an autonomous as well as an intelligent actor. By enabling these systems to perceive, measure and evaluate the consequences of their actions and the operational quality of their judgement, these perception-action-evaluation loops will transform them into responsible, learning agents. To design, direct and control such recently established entities is a gigantic scientific problem. It is no longer theoretical: the movement is underway, on a planetary scale of almost unimaginable complexity! It is first and foremost a challenge to the sciences of matter and engineering.<!--more-->

But how will these new entities emerge? **As such, we are faced with an Argus with billions of eyes and ears in addition to the capacity for action, and with infinite memory.** What will be their characteristics? How shall we integrate them into human society? How will humans adapt to this new situation? This is the second challenge: **a challenge to our societies created by the technology we have brought into the world.** What rights, what duties, what values, what police for these entities? These questions are all the more difficult because such entities will remain in continuity with legal entities and natural persons, in technical, functional, economic and legal hybrids. In fact, they already are!

This is a challenge facing humanities and social sciences. In this spirit, it is worth mentioning the notion of the semantic Rubicon, created by Kindberg and Fox, which defines **the limit between what is left to the appreciation (or decision) of the human, and what is left to the appreciation of the machine**. This notion, which is little known today, will become an essential issue in many fields. In short, our civilisation is going to become hybrid, and not just for meetings. The social, economic, political and anthropological management of this evolution is a huge challenge.

The last challenge is that of **global transitions: climatic, ecological, economic,** and so on. Their urgency is obvious. The complexity of the problems, and the need for solutions finely adapted locally, taking into account a multitude of parameters, are challenges on the scale of these digital Argus that we are creating. How can we make problems and solutions meet, can we find more efficient methods of governance of research and technology than the famous garbage can theory of Cohen, March and Olsen, where the problem bearers meet the solution bearers somewhat by chance? Or, to quote them: _“one can view a choice opportunity as a garbage can into which various kinds of problems and solutions are dumped by participants as they are generated”._ Can we steer research in directions that will facilitate productive encounters? We can hope so…

This is what we will be trying to do in ICA4: some of the best minds in the world will, in a collective effort, try to identify the important questions that the field needs to ask itself, and perhaps also point to ways of solving them...

Later on, [**Professor Shimon Ullman**](https://www.intercontinental-academia.org/mentors#ullman "Shimon Ullman") argued that with the amazing rate of advances in AI, anticipating correctly what will happen on a time scale of decades is an impossible task, and potentially embarrassing in retrospect.

As he sees it, a major general challenge and an open question would be: **will current AI methods reach or approach some form of "true", human-like understanding?**

This problem is common to different areas of AI. There has been impressive progress in a range of visual tasks (including object recognition, segmentation, image captioning and others), but we still struggle with the question: **do AI vision systems really understand the scene they are looking at?**

A preliminary challenge in tackling the problem of achieving human-like understanding is **developing methods for evaluating the degree of understanding obtained by AI systems**. ‘Understanding’ is not a case of all-or-none, but a matter of degree, and perhaps of different types of understanding. In any domain, understanding can range from a lack of understanding to understanding some of the principles, to a deep and detailed understanding. In the case of vision, directions I consider relevant for evaluating understanding include the ability to obtain meaningful scene structures, to reach broad semantic generalization, and to justify conclusions. However, creating useful systematic methods for evaluating understanding along such directions is a complex open challenge. As evaluation methods develop, the experience will show that **current AI methods do not give rise by themselves to the emergence of human-like understanding**. We will then face a fundamental challenge of identifying the missing ingredients, and of finding methods that lead to deeper, more human-like understanding. The process will be gradual. Indeed, **reaching deep and detailed human-like understanding will prove to be a challenge for decades...**

[**Professor Karen Yeung**](/mentors#yeung "Karen Yeung") recognised two main challenges which include achieving the legal, cultural and organisational frameworks that will ensure appropriate (1) **governance of data** and (2) **governance of AI,** in ways that will be widely accepted as ensuring appropriate protection for individuals and organisations in ways that broadly align with core values upon which liberal democratic societies are grounded. In such ways, individuals, groups, and the community at large could then benefit from the value of data-driven technologies (including AI). She then further explained:

**The data governance challenge:**

Achieving this will be one of the greatest challenges of the new digitised and "datafied" era into which we are transitioning given the unique properties of digital data: permanent, instantaneously reproducible without loss of quality at scale. Hence the marks that **we now leave in our digital traces have vastly different implications from the paper trails of an analogue world**. Compare, for example, the criminal record stored on a little card kept in a local police office that testifies to the exuberance of youth, and the single Kodak photo of a naked photo sent by a person to her lover. At the same time, we have no reliable and trustworthy institutional mechanisms for ensuring and guaranteeing the provenance, accuracy and conditions under which data-sets have been collected, and that they are being utilised to create algorithmic models which are 'fit for purpose' so that the resulting predictions appropriately and meaningfully represent the phenomena they are claimed (by their creators) to represent.

**The governance of AI** **challenge:**

The highly sophisticated, opaque yet powerful capacities of these techniques and their embedding into myriad social applications have already demonstrated their adverse consequences - for individuals, groups and communities. No doubt there will be many that we have not yet properly identified or understood, particularly as new applications emerge and new vulnerabilities and problems are created. They are increasingly embedded into complex socio-technical systems that display emergent properties that are unstable and therefore uncertain. While these technologies have already delivered valuable benefits at the individual and collective level, many promises are made about their capabilities: yet whether these promises will be translated into real-world benefits of the kind that are promised remains a _very_ open question. History has shown just that on many occasions. This is particularly problematic concerning the AI applications that are dependant upon data collected through the continuous and pervasive 'uberveillance' of individual behaviour and activity in ways that are already used in ways that are contrary to the interests, welfare and autonomy of persons.