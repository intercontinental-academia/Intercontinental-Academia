---
tags:
- Paris IAS
- ICA4
- Artificial Intelligence
- IEA de Paris
- Intelligence
published: true
pinned: false
post_title: 'Keeping Up with the ICA4: What''s happening each day at Paris IAS?'
date: 2021-10-19T22:00:00Z
authors:
- name: Atrina Oraee
images:
- "/image.png"
- "/snapseed-6.jpg"
- "/img_4211.jpg"
- "/snapseed-7.jpg"
youtube_video_id: ''
audio: []

---
Each day, the Fellows and their Mentors meet for **a closed 3-hour seminar**, during which two mentors launch the discussion with a presentation. Upon completion of the seminar, the Fellows then meet for 45 minutes to list the **key takeaways and ideas** that have emerged from the discussion, followed by a **collective brainstorming session**. This ensures that the output of collective intelligence is collected, formatted and capitalised.

The other half of the day is left free for participants to **reflect on the scientific discussions** in small groups. Such discussions are occasionally complemented by **lectures from the Chairs**. Finally, the Academia **travels to meet researchers** from some of the most prestigious universities in Paris. This includes a day at **Paris-Saclay**, a day at **Sorbonne University**, and finally, a day at the **ENS**. Upon completion of every morning's closed seminar at IAS, meetings and conferences are organised to encourage collective discussions and networking. The summary of each day is capitalised on the **ICA4 blog**. The following blogpost capitalises the key takeaways of each day’s sessions, as well as summarising the highlights.<!--more-->

# **Day 1: How it started…**

Chair: [Laura Candiotto](https://www.intercontinental-academia.org/fellows#candiotto "Laura Candiotto")

Scribe: [Massimiliano Di Luca](https://www.intercontinental-academia.org/fellows#luca "Massimiliano Di Luca")

**Perception, prediction, and pleasure: What can music teach us about neurocognition/intelligence?**

Presented by [_Robert Zatorre_](https://www.intercontinental-academia.org/mentors#zatorre "Robert Zatorre")

It was stated during the seminar that the brain represents the properties of the environment and guides behaviour through evaluation and reward. Aesthetic pleasure can be defined as the phylogenetically older system that is centred on the striatum.

Moreover, results of the relation between connectivity of the auditory cortex with the striatum and several behavioural results were presented (e.g. related to amusia, music-specific anhedonia). Dynamic causal modelling and predictive coding frameworks have been presented as possible explanations of the relationship between learning and reward in music. Predictions make the rewards evolve from a biological event to the expectation of the event.

Through the post-seminar collective discussions, the relevance of affective experience (pleasure and fear) in learning was emphasised. Discussions concluded with a rather open-ended question, leaving ICA4 Fellows wondering about whether or not AI should have a similar system for learning, and how should the reward and punishment be differentiated?" Maybe AI does not need to understand or experience human emotions; it just needs to behave like a human by capturing the features of a dataset that correctly describes the behaviour...

**High Energy Physics: Successes, Challenges and Magic**

Presented by [_Eliezer Rabinovici_](https://www.intercontinental-academia.org/about/ica4#rabinovici "Eliezer Rabinovici")

It was discussed that observing natural phenomena can motivate scientific enquiry and drive us to understand the unknown. Moreover, equations are a way to increase predictability. However, a single, compact and reductionist explanation for all phenomena in the universe may not necessarily exist. The scientific method requires that results are reproducible. The correspondence principle requires that new theories can explain all phenomena for which a preceding theory was valid. To understand a phenomenon, one has to identify the relevant players and determine the correct explanation scale.

**In AI We Trust: Power, illusion and control of predictive algorithms**

Presented by [_Helga Nowotny_](http://helga-nowotny.eu "Helga Nowotny")

The session began with introducing the concept of singularity and defining it as a tipping point: a change of state that can lead to the collapse of a system. In an attempt to define Ethical AI, examples such as Transhumanism (ideas of transcending the limitations of a mortal body through information sharing) were discussed. Furthermore, the illusion that AI knows humans better than humans know themselves was elaborated, ultimately concluding by mentioning the existence of a possibility for human beings to both profit or suffer from an AI system depending on how it is applied.

**"The future needs wisdom”**: a urgent need to institutionalise context sensitivity, rather than creating a standardised system to control AI, was discussed and collectively developed. This lead to further debates regarding the concentration of technology advancement and its deteriorating impact on inequality. Thus, a global agreement is necessary to control AI, although it is currently almost impossible to obtain! Therefore, we should educate AI as a child of humanity that can grow to contribute to society. AI research is undertaken at such a massive scale that it requires global efforts which go beyond a single country. Scientists are paid by society, and their curiosity-led work should return to society as a whole...