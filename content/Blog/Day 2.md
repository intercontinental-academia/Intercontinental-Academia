---
tags:
- Consciousness
- Responsibility
- Ethics
- Economics
- Data Science
- Human Rights
- AI Apllications
published: true
pinned: false
post_title: 'Day 2: "In AI we trust"...or not!'
date: 2021-10-18T23:00:00Z
authors:
- name: Atrina Oraee
images:
- "/snapseed-10.jpg"
- "/snapseed-32.jpg"
- "/snapseed-3.jpg"
- "/220cd751-06ee-44b0-8ca1-458e64780c70-1.JPG"
- "/image.png"
- "/img_4432-2.jpg"
- "/2fa0618b-acab-4552-b468-62a883046858.JPG"
- "/snapseed-11.jpg"
- "/snapseed-29.jpg"
youtube_video_id: ''
audio: []

---
The ICA4 continued onto the second day, through which three seminars took place with mentors who had joined the first session in Paris from around the world!

The first lecture was by [_Robert Aumann_](/mentors#aumann "Robert Aumann"), a Nobel prize laureate, who focused on the convoluted concept of **consciousness** and its counterparts.

This was followed by a lecture from [_Karen Yeung_](/mentors#yeung "Karen Yeung"), who offered a rather critical point of view on the prevalence of AI, as well as some of its surrounding **myths and misconceptions**. She then went on to explain how **responsibility** should be re-defined to consider the **unintended impact(s) of AI in human societies**.

Finally, [_Raouf Boucekkine _](/about/ica4#boucekkine "Raouf Boucekkine")took the fellows for an exploration into the world of economics and finance, using the concept of **equilibrium** as an example to illustrate the difference between disciplines: **mainstream economics VS. statistical physics!**<!--more-->

**Why Consciousness?**

Presented by [**_Robert Aumann_**](/mentors#aumann "Robert Aumann")

Essentially, the seminar was focused on the purpose which consciousness serves. Consciousness was defined as the ability to do the following:

* Perceive
* Feel (emotions)
* Think/intend
* Carry out intentions (volition)

Of all the above, perceiving, thinking/intending, and carrying out intentions may be done by machines. However, feelings and emotions belong exclusively to human beings. In such a context, it may be argued that the evolutionary function of consciousness is to enable the operation of emotions. This being said, we currently have no idea about how does consciousness work. Although considerable progress has been made in AI, Artificial Emotions (AE) has remained rather untouched.

**Myths and misunderstandings about responsibility for the unintended impact of AI**

Presented by [**_Karen Yeung_**](/mentors#yeung "Karen Yeung")

The talk mostly focused on responsibility for the unintended impact of Artificial Intelligence, based on the presenter's Council of Europe study. It was argued that Machine Learning's (ML) capacity to enable task automation and machine "autonomy" raise important questions about **responsibility**. Thus, responsibility-relevant attributes of ML were identified, for which an illustration is the data-driven profiling of individuals, and other ML applications, which may hold adverse impacts on human rights, on both individual and collective levels.  
While responsibility is important for human beings, who are considered as moral agents, to maintain peaceful social co-operation within the community, only a few studies have focused on tackling the fundamental role of responsibility for individuals, as well as the society.

The impacts produced by complex socio-technical systems using ML technologies have generated a range of concerns that fall under the heading of "algorithmic responsibility". While existing laws have an important role to play in ensuring the accountability of algorithmic systems, the implications of these technologies for their interference with human rights need to be studied further. This has been the primary focus of Karen Yeung's research.

In a nutshell, two dimensions of responsibility are required:

* **Historic or retrospective responsibility:** responsibility for conduct and events that occurred in the past
* **Prospective responsibility:** roles and tasks that look to the future

Finally, five common **myths and misunderstandings** concerning responsibility for the unintended adverse impacts of AI were identified:

* Need for effective and legitimate mechanisms to protect human rights from AI applications.
* Identifications of the appropriate responsibility model for allocating, distributing and preventing the various threats and risks.
* Responsibility of states to ensure that these policy choices are made in a transparent and democratic manner, in order to effectively protect human rights.
* Need for more interdisciplinary research
* Application of the fundamental principle of reciprocity so as not to allow those who develop and run our advanced digital technologies and systems to increase and exercise their power without responsibility.

**Data science and deep learning vs theory: two examples from economics and finance**

Presented by [**_Raouf Boucekkine_**](/about/ica4#boucekkine "Raouf Boucekkine")

The session included discussions on Data Science, Machine Learning (ML), and some relevant theories in the field of economics and finance that share common disciplines. Certain examples from macroeconomics, in which characteristics of the underlying mechanisms for complex systems are of great interest, were then discussed in more detail. In such context, a misunderstanding between different disciplines was highlighted: **the concept of equilibrium** is of great significance in mainstream macroeconomics, whereas this is not the case for statistical physics (e.g., the "equilibrium" bias outside the econ area, discussed by Bonneuil & Boucekkine (2020)). Finally, the use of various **methods** and approaches, such as DSGE (Dynamic Stochastic General Equilibrium), ABM (Agent-Based Modeling), and Neural Network-Based methods, in the field of macroeconomics were discussed.

Scribe: [_Tahina Ralitera_](/fellows#ralitera "Tahina Ralitera")

Chair: [_Benjamin Guedj_](/fellows#guedj "Ben Guedj")